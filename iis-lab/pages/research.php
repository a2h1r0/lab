<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>知的インタラクティブシステム研究室 - 研究紹介</title>

  <!-- 共有ファイル -->
  <?php include($_SERVER['DOCUMENT_ROOT'].'/iis-lab/include.php'); ?>
  <!-- 個別CSS -->
  <link rel="stylesheet" type="text/css" href="/iis-lab/css/research.css">
</head>

<!-- ヘッダー埋め込み -->
<?php include($_SERVER['DOCUMENT_ROOT'].'/iis-lab/parts/header.php'); ?>

<body>
  <div class="main">
    <!-- articleごとに研究をまとめる -->
    <!-- 新しいのを上に -->

    <article class="research">
      <h1>スマートフォンの通知の取られ方にもとづくユーザおよび端末の状態識別手法</h1>
      <figure>
        <a href="/iis-lab/figures/research/dicomo2019_sawano.jpg" data-lightbox="group"><img src="/iis-lab/figures/research/dicomo2019_sawano.jpg"></a>
      </figure>
      <p>さまざまなセンサを搭載したスマートフォンやウェアラブルデバイスの普及により，時間や場所を問わず人間の行動や生体情報，周囲の状況を認識できるようになった．センサデータから人間の行動や状況を推定する処理は，正解情報（アノテーション）が付与されたデータセットを用いてユーザの行動や状況を解釈するモデルを事前に構築する必要がある．そのため，モデルの高性能化や性能評価のために多量かつ多様なアノテーション付きデータセットが必要となる．加速度センサの値は後から見てユーザの状況を判断することは困難なため，加速度データにアノテーションを付与する手法が必要である．本研究では，スマートフォンなどの端末が生成する通知に対するユーザの対応からユーザや端末の状況を推定する手法を提案する．通知発生から削除までの応答時間による状態推定と端末内の加速度センサの値を利用した状態推定を併用して，ユーザや端末の状態推定を行い，推定結果の確信度がきわめて高い場合にセンサデータへのアノテーション付与を行う．評価実験より，アノテーションを付与したい7つの状態に対して，ユーザ非依存とユーザ依存の実験を行い，平均適合率0.769と0.963を得た．また，自然環境における実験も行い，ユーザが反応した45個の通知に対して，25個に正しいアノテーションが付与され，19個にアノテーション付与を行わず，誤って付与したアノテーションは1個であった．<br>
        <p class="author">[DICOMO2019 / 2020年度M2：澤野 亮太]</p>
      </p>
    </article>

    <article class="research">
      <h1>アクティブ音響センシングを用いた野菜認識調理道具</h1>
      <figure>
        <a href="/iis-lab/figures/research/dicomo2019_nishii.jpg" data-lightbox="group"><img src="/iis-lab/figures/research/dicomo2019_nishii.jpg"></a>
      </figure>
      <p>人は多くの場面で道具を使用して衣食住などの生産活動を行ってきた．こういった場面において，人がインタラクションを行った物体を認識できれば有用であるが，既存手法は複数の観点で課題を残していた．本研究では，ユーザが道具を介して物体とインタラクションをする場面において，ユーザの使用道具にアクティブ音響センシング技術を適用させることで，物体認識を効果的に行う手法を提案する．提案手法では，ユーザが使用する道具にスピーカとマイクを取り着け，スピーカから音響信号を流し，道具が物体に接触した際に，物体を伝搬した音響信号をマイクから取得し，その音響信号の周波数特性を解析することで，物体を認識する．このように提案手法では，認識したい物体にユーザの使用道具が接触することと，認識したい物体が固有の音響特性をもつことを利用している．本稿では，調理や食事といった道具を用いて食材とインタラクションをする場面を対象にして，食材を挟むトング型デバイスと，切る包丁型デバイスを実装した．そして，提案手法の有効性を評価する実験を7種類の野菜をもとに3つ行い，いずれの実験においても，88％以上の精度で野菜の種類を認識できることを確認した．<br>
        <p class="author">[DICOMO2019 / 2020年度M2：西井 遥菜]</p>
      </p>
    </article>

    <article class="research">
      <h1>心電と脈波の時間差を用いたウェアラブル端末装着位置推定手法</h1>
      <figure>
        <a href="/iis-lab/figures/research/dicomo2019_yoshida.jpg" data-lightbox="group"><img src="/iis-lab/figures/research/dicomo2019_yoshida.jpg"></a>
      </figure>
      <p>種々のセンサを搭載したウェアラブルデバイスの普及により，時間や場所を問わず人間の行動や状況をセンシングしてデータを収集できるようになった．任意の身体部位に装着できるセンサを1箇所に装着すると，装着位置によって処理モデルを切り替える必要がある．また，同一形状のセンサを複数装着する場合，センサを区別するために身体部位を動かしてデータの変化を見る作業が必要である．そのため，ウェアラブルデバイスをさまざまな身体部位に自由に装着する環境において，デバイスの装着部位を動的に推定する手法が必要である．ウェアラブルデバイスの装着部位を推定する手法として，ウェアラブルデバイスの加速度センサや角速度センサから得られた時系列データを用いた手法が提案されている．これらの研究では歩行動作などの特定行動をしなければ装着位置の推定ができないという問題点がある．本研究では装着者に特定の行動を強いることなく，ウェアラブルデバイスの装着位置を推定する手法を提案する．提案手法は心電センサ（ECG）で得られた心拍と脈拍センサで得られた脈波との時間差を推定し，推定された時間差からデバイスの装着位置を推定する．脈拍センサはウェアラブルデバイスに搭載されていると仮定している．男性5名から2分間の心電と脈波のデータを身体部位15箇所から収集して，提案手法の評価実験を行った結果，平均F値は0.805となった．特に，被験者がデバイスを装着してから約20秒間のデータを用いることで左耳と右手指は0.9を超えるF値が得られた．<br>
        <p class="author">[DICOMO2019 / 2020年度M2：吉田 航輝]</p>
      </p>
    </article>

    <article class="research">
      <h1>ドアの開閉動作に基づく個人識別システムの提案</h1>
      <figure>
        <a href="/iis-lab/figures/research/dicomo2019_fukao.jpg" data-lightbox="group"><img src="/iis-lab/figures/research/dicomo2019_fukao.jpg"></a>
      </figure>
      <p>複数人で共有する部屋は日常生活において多く利用されている．個人認識のための手法は多く提案されているが，入退室者の認識にあたっては，ユーザに不要な作業や機器携帯を要するなど心理的・身体的な負担の観点で課題がある．本研究では入退室に伴う動作であるドアの開閉動作を利用することで，入退室者を認識する手法を提案する．提案手法は，ドアの開閉動作にはユーザごとに異なる特徴があるとする仮説にもとづく．そして，ドアノブに角速度センサを設置し，ユーザが入退室した際のドアの開閉動作から8種類の特徴量を抽出し，機械学習を用いて入退室者を認識する．提案手法のプロトタイプシステムを一般的なレバーハンドル式のドアに実装し，一般家庭を想定して被験者4名を対象に実験を行い，入室動作と退室動作の認識をそれぞれ行った．その結果，退室動作のF値は最大0.90で認識でき，また，入室動作のF値は最大0.73で認識でき，提案手法の実現可能性を確認した．<br>
        <p class="author">[DICOMO2019 / 2019年度卒業：深尾 あかり]</p>
      </p>
    </article>

    <article class="research">
      <h1>視線情報を用いた歩行中の迷子状態の検知手法の検討</h1>
      <figure>
        <a href="/iis-lab/figures/research/dicomo2019_miyamae.jpg" data-lightbox="group"><img src="/iis-lab/figures/research/dicomo2019_miyamae.jpg"></a>
      </figure>
      <p>本研究では視線計測装置から得られた視線データおよび頭部の加速度，角速度データから人の迷子状態を検出する手法を提案する．提案手法は迷子区間がアノテーションされた学習データから迷子区間のモチーフと非迷子区間のモチーフを抽出し，迷子区間と非迷子区間に共通で現れるモチーフを迷子区間のモチーフから除去することで迷子区間特有のモチーフを抽出する．大阪地下街で実施した評価実験の結果より，迷子区間特有のモチーフを抽出できたが，他セッション，他ユーザへの適用にはさらなる調査が必要であることが分かった．<br>
        <p class="author">[DICOMO2019 / 2018年度卒業：宮前 貴大]</p>
      </p>
    </article>
  </div>
</body>

<!-- フッター埋め込み -->
<?php include($_SERVER['DOCUMENT_ROOT'].'/iis-lab/parts/footer.php'); ?>
</html>
